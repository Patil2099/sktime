{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting with sktime\n",
    "\n",
    "This notebook give a tutorial on the forecasting learning task supported by `sktime`.\n",
    "\n",
    "In forecasting, past data is used to make temporal forward predictions of a time series. This is notably different from tabular prediction tasks supported by `scikit-learn` and similar libraries.\n",
    "\n",
    "\n",
    "<img src=\"img/forecasting.png\" width=750 />\n",
    "\n",
    "`sktime` provides a common, `scikit-learn`-like interface to a variety of classical and ML-style forecasting algorithms, together with tools for building pipelines and composite machine learning models, including temporal tuning schemes, or reductions such as walk-forward application of `scikit-learn` regressors.\n",
    "\n",
    "Further references:\n",
    "* for further details on how forecasting is different from supervised prediction Ã  la `scikit-learn`, and pitfalls of misdiagnosing forecasting as supervised prediction, have a look at [this notebook](./01a_forecasting_sklearn.ipynb)\n",
    "* for a scientific reference, take a look at [our paper on forecasting with sktime](https://arxiv.org/abs/2005.08067) in which we discuss `sktime`'s forecasting module in more detail and use it to replicate and extend the M4 study."
   ]
  },
  {
   "source": [
    "#### package imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this for running this notebook with a local version of sktime\n",
    "# from os import sys\n",
    "# sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic forecasting workflows"
   ]
  },
  {
   "source": [
    "This section explains the basic forecasting workflows, and key interface points for it.\n",
    "\n",
    "We cover the following three workflows:\n",
    "\n",
    "* basic deployment workflow: batch fitting and forecasting\n",
    "* basic evaluation workflow: evaluating a batch of forecasts against ground truth observations\n",
    "* advanced deployment workflow: fitting and rolling updates/forecasts\n",
    "* advanced evaluation worfklow: using rolling forecast splits and computing split-wise and aggregate errors, including common back-testing schemes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data container format\n",
    "\n",
    "All workflows make common assumptions on the input data format.\n",
    "\n",
    "`sktime` uses `pandas` for representing time series:\n",
    "\n",
    "* `pd.Series` for univariate time series and sequences\n",
    "* `pd.DataFrame` for multivariate time series and sequences\n",
    "\n",
    "The `Series.index` and `DataFrame.index` are used for representing the time series or sequence index. `sktime` supports pandas integer, period and timestamp indices.\n",
    "\n",
    "NOTE: at current time (v0.6x), forecasting of multivariate time seres is not a stable functionality, this is a priority roadmap item. Multivariate exogeneous time series are part of stable functionality."
   ]
  },
  {
   "source": [
    "**Example:** as the running example in this tutorial, we use a textbook data set, the Box-Jenkins airline data set, which consists of the number of monthly totals of international airline passengers, from 1949 - 1960. Values are in thousands. See \"Makridakis, Wheelwright and Hyndman (1998) Forecasting: methods and applications\", exercises sections 2 and 3."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.utils.plotting import plot_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:05.849641Z",
     "iopub.status.busy": "2021-04-10T16:07:05.849188Z",
     "iopub.status.idle": "2021-04-10T16:07:06.049023Z",
     "shell.execute_reply": "2021-04-10T16:07:06.049499Z"
    }
   },
   "outputs": [],
   "source": [
    "y = load_airline()\n",
    "\n",
    "# plotting for visualization\n",
    "plot_series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, users are expected to use the in-built loading functionality of `pandas` and `pandas`-compatible packages to load data sets for forecasting, such as `read_csv` or the `Series` or `DataFrame` constructors if data is available in another in-memory format, e.g., `numpy.array`.\n",
    "\n",
    "`sktime` forecasters may accept input in `pandas`-adjacent formats, but will produce outputs in, and attempt to coerce inputs to, `pandas` formats.\n",
    "\n",
    "NOTE: if your favourite format is not properly converted or coerced, kindly consider to contribute that functionality to `sktime`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Basic deployment workflow - batch fitting and forecasting"
   ]
  },
  {
   "source": [
    "The simplest use case workflow is batch fitting and forecasting, i.e., fitting a forecasting model to one batch of past data, then asking for forecasts at time point in the future.\n",
    "\n",
    "The steps in this workflow are as follows:\n",
    "\n",
    "1. preparation of the data\n",
    "2. specification of the time points for which forecasts are requested. This uses a `numpy.array` or the `ForecastingHorizon` object.\n",
    "3. specification and instantiation of the forecaster. This follows a `scikit-learn`-like syntax; forecaster objects follow the familiar `scikit-learn` `BaseEstimator` interface.\n",
    "4. fitting the forecaster to the data, using the forecaster's `fit` method\n",
    "5. making a forecast, using the forecaster's `predict` method\n",
    "\n",
    "The below first outlines the vanilla variant of the basic deployment workflow, step-by-step.\n",
    "\n",
    "At the end, one-cell workflows are provided, with common deviations from the pattern (Sections 1.2.1 and following)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### step 1 - preparation of the data\n",
    "\n",
    "as discussed in Section 1.1, the data is assumed to be in `pd.Series` or `pd.DataFrame` format."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.utils.plotting import plot_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the example, we use the airline data set.\n",
    "y = load_airline()\n",
    "plot_series(y)"
   ]
  },
  {
   "source": [
    "#### step 2 - specifying the forecasting horizon"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to specify the forecasting horizon and pass that to our forecasting algorithm.\n",
    "\n",
    "There are two main ways:\n",
    "\n",
    "* using a `numpy.array` of integers. This assumes either integer index or periodic index (`PeriodIndex`) in the time series; the integer indicates the number of time points or periods ahead we want to make a forecast for. E.g., `1` means forecast the next period, `2` the second next period, and so on.\n",
    "* using a `ForecastingHorizon` object. This can be used to define forecast horizons, using any supported index type as an argument. No periodic index is assumed.\n",
    "\n",
    "Forecasting horizons can be absolute, i.e., referencing specific time points in the future, or relative, i.e., referencing time differences to the present. As a default, the present is that latest time point seen in any `y` passed to the forecaster.\n",
    "\n",
    "`numpy.array` based forecasting horizons are always relative; `ForecastingHorizon` objects can be both relative and absolute. In particular, absolute forecasting horizons can only be specified using `ForecastingHorizon`."
   ]
  },
  {
   "source": [
    "##### using a numpy forecasting horizon"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:06.222860Z",
     "iopub.status.busy": "2021-04-10T16:07:06.222322Z",
     "iopub.status.idle": "2021-04-10T16:07:06.224682Z",
     "shell.execute_reply": "2021-04-10T16:07:06.225165Z"
    }
   },
   "outputs": [],
   "source": [
    "fh = np.arange(1, 37)\n",
    "fh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will ask for monthly predictions for the next three years, since the original series period is 1 month.\n",
    "In another example, to predict only the second and fifth month ahead, one could write:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "fh = np.array([2, 5])  # 2nd and 5th step ahead\n",
    "```"
   ]
  },
  {
   "source": [
    "##### Using a `ForecastingHorizon` based forecasting horizon\n",
    "\n",
    "The `ForecastingHorizon` object takes absolute indices as input, but considers the input absolute or relative depending on the `is_relative` flag.\n",
    "\n",
    "`ForecastingHorizon` will automatically assume a relative horizon if temporal difference types from `pandas` are passed; if value types from `pandas` are passed, it will assume an absolute horizon.\n",
    "\n",
    "To define an absolute `ForecastingHorizon` in our example:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.base import ForecastingHorizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:06.229051Z",
     "iopub.status.busy": "2021-04-10T16:07:06.228401Z",
     "iopub.status.idle": "2021-04-10T16:07:06.230685Z",
     "shell.execute_reply": "2021-04-10T16:07:06.231173Z"
    }
   },
   "outputs": [],
   "source": [
    "fh = ForecastingHorizon(pd.PeriodIndex(pd.date_range('1961-01', periods=36, freq='M')), is_relative=False)\n",
    "fh"
   ]
  },
  {
   "source": [
    "`ForecastingHorizon`-s can be converted from relative to absolute and back via the `to_relative` and `to_absolute` methods. Both of these conversions require a compatible `cutoff` to be passed:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = pd.Period('1960-12', freq='M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh.to_relative(cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh.to_absolute(cutoff)"
   ]
  },
  {
   "source": [
    "#### step 3 - specifying the forecasting algorithm\n",
    "\n",
    "To make forecasts, a forecasting algorithm needs to be specified. This is done using a `scikit-learn`-like interface. Most importantly, all `sktime` forecasters follow the same interface, so the preceding and remaining steps are the same, no matter which forecaster is being chosen.\n",
    "\n",
    "For this example, we choose the naive forecasting method of predicting the last seen value. More complex specifications are possible, using pipeline and reduction construction syntax; this will be covered later in Section 2."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.naive import NaiveForecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = NaiveForecaster(strategy=\"last\")"
   ]
  },
  {
   "source": [
    "#### step 4 - fitting the forecaster to the seen data\n",
    "\n",
    "Now the forecaster needs to be fitted to the seen data:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.fit(y)"
   ]
  },
  {
   "source": [
    "#### step 5 - requesting forecasts\n",
    "\n",
    "Finally, we request forecasts for the specified forecasting horizon. This needs to be done after fitting the forecaster:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forecaster.predict(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting predictions and past data\n",
    "plot_series(y, y_pred, labels=[\"y\", \"y_pred\"])"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 1.2.1 the basic deployment workflow in a nutshell\n",
    "\n",
    "for convenience, we present the basic deployment workflow in one cell.\n",
    "This uses the same data, but different forecaster: predicting the latest value observed in the same month."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: data specification\n",
    "y = load_airline()\n",
    "\n",
    "# step 2: specifying forecasting horizon\n",
    "fh = np.arange(1, 37)\n",
    "\n",
    "# step 3: specifying the forecasting algorithm\n",
    "forecaster = NaiveForecaster(strategy=\"last\", sp=12)\n",
    "\n",
    "# step 4: fitting the forecaster\n",
    "forecaster.fit(y)\n",
    "\n",
    "# step 5: querying predictions\n",
    "y_pred = forecaster.predict(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: plotting predictions and past data\n",
    "plot_series(y, y_pred, labels=[\"y\", \"y_pred\"])"
   ]
  },
  {
   "source": [
    "#### 1.2.2 forecasters that require the horizon already in `fit`\n",
    "\n",
    "Some forecasters need the forecasting horizon provided already in `fit`. Such forecasters will produce informative error messages when it is not passed in `fit`. All forecaster will remember the horizon when already passed in `fit` for prediction. The modified workflow to allow for such forecasters in addition is as follows:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: data specification\n",
    "y = load_airline()\n",
    "\n",
    "# step 2: specifying forecasting horizon\n",
    "fh = np.arange(1, 37)\n",
    "\n",
    "# step 3: specifying the forecasting algorithm\n",
    "forecaster = NaiveForecaster(strategy=\"last\", sp=12)\n",
    "\n",
    "# step 4: fitting the forecaster\n",
    "forecaster.fit(y, fh=fh)\n",
    "\n",
    "# step 5: querying predictions\n",
    "y_pred = forecaster.predict()"
   ]
  },
  {
   "source": [
    "#### 1.2.3 forecasters that can make use of exogeneous data\n",
    "\n",
    "Many forecasters can make use of exogeneous time series, i.e., other time series that are not forecast, but are useful for forecasting `y`. Exogeneous time series are always passed as an `X` argument, in `fit`, `predict`, and other methods (see below). Exogeneous time series should always be passed as `pandas.DataFrames`. Most forecasters that can deal with exogeneous time series will assume that the time indices of `X` passed to `fit` are a super-set of the time indices in `y` passed to `fit`; and that the time indices of `X` passed to `predict` are a super-set of time indices in `fh`, although this is not a general interface restriction. Forecasters that do not make use of exogeneous time series still accept the argument (and do not use it internally).\n",
    "\n",
    "The general workflow for passing exogeneous data is as follows:"
   ],
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:06.475031Z",
     "iopub.status.busy": "2021-04-10T16:07:06.473831Z",
     "iopub.status.idle": "2021-04-10T16:07:06.613175Z",
     "shell.execute_reply": "2021-04-10T16:07:06.613700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: data specification\n",
    "y = load_airline()\n",
    "# we create some dummy exogeneous data\n",
    "X = pd.DataFrame(index=y.index)\n",
    "\n",
    "# step 2: specifying forecasting horizon\n",
    "fh = np.arange(1, 37)\n",
    "\n",
    "# step 3: specifying the forecasting algorithm\n",
    "forecaster = NaiveForecaster(strategy=\"last\", sp=12)\n",
    "\n",
    "# step 4: fitting the forecaster\n",
    "forecaster.fit(y, X=X, fh=fh)\n",
    "\n",
    "# step 5: querying predictions\n",
    "y_pred = forecaster.predict(X=X)"
   ]
  },
  {
   "source": [
    "NOTE: as in workflows 1.2.1 and 1.2.2, some forecasters that use exogeneous variables may also require the forecasting horizon only in `predict`. Such forecasters may also be called with steps 4 and 5 being\n",
    "```python\n",
    "forecaster.fit(y, X=X)\n",
    "y_pred = forecaster.predict(fh=fh, X=X)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### basic evaluation workflow - evaluating a batch of forecasts against ground truth observations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Next we will define a forecasting task.\n",
    "\n",
    "* We will try to predict the last 3 years of data, using the previous years as training data. Each point in the series represents a month, so we should hold out the last 36 points as test data, and use 36-step ahead forecasting horizon to evaluate forecasting performance.\n",
    "* We will use the sMAPE (symmetric mean absolute percentage error) to quantify the accuracy of our forecasts. A lower sMAPE means higher accuracy.\n",
    "    * Sktime makes the sMAPE available as the `mean_absolute_percentage_error()` when setting the argument `symmetric=True`, whichi is the default\n",
    "\n",
    "We can split the data as follows:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_selection import temporal_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = temporal_train_test_split(y, test_size=36)\n",
    "plot_series(y_train, y_test, labels=[\"y_train\", \"y_test\"])\n",
    "print(y_train.shape[0], y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting with sktime\n",
    "\n",
    "### Reduction: from forecasting to regression\n",
    "\n",
    "`sktime` provides a meta-estimator for this approach, which is:\n",
    "\n",
    "* **modular** and **compatible with scikit-learn**, so that we can easily apply any scikit-learn regressor to solve our forecasting problem,\n",
    "* **tuneable**, allowing us to tune hyper-parameters like the window length or strategy to generate forecasts\n",
    "* **adaptive**, in the sense that it adapts the scikit-learn's estimator interface to that of a forecaster, making sure that we can tune and properly evaluate our model\n",
    "\n",
    "<img src=\"img/forecasting-to-regression-reduction.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:07.430563Z",
     "iopub.status.busy": "2021-04-10T16:07:07.424929Z",
     "iopub.status.idle": "2021-04-10T16:07:07.432645Z",
     "shell.execute_reply": "2021-04-10T16:07:07.433155Z"
    }
   },
   "outputs": [],
   "source": [
    "y = load_airline()\n",
    "y_train, y_test = temporal_train_test_split(y, test_size=36)\n",
    "print(y_train.shape[0], y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:07.439875Z",
     "iopub.status.busy": "2021-04-10T16:07:07.439381Z",
     "iopub.status.idle": "2021-04-10T16:07:07.650204Z",
     "shell.execute_reply": "2021-04-10T16:07:07.650693Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "regressor = KNeighborsRegressor(n_neighbors=1)\n",
    "forecaster = make_reduction(regressor, window_length=15, strategy=\"recursive\")\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example we use the \"recursive\" strategies. Other implemented strategies are: \n",
    "* \"direct\", \n",
    "* \"dirrec\", \n",
    "* \"multioutput\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical forecasters\n",
    "\n",
    "`sktime` has a number of statistical forecasting algorithms, based on implementations in statsmodels. For example, to use exponential smoothing with an additive trend component and multiplicative seasonality, we can write the following.\n",
    "\n",
    "Note that since this is monthly data, the seasonal periodicity (sp), or the number of periods per year, is 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:07.657376Z",
     "iopub.status.busy": "2021-04-10T16:07:07.656901Z",
     "iopub.status.idle": "2021-04-10T16:07:07.943024Z",
     "shell.execute_reply": "2021-04-10T16:07:07.943679Z"
    }
   },
   "outputs": [],
   "source": [
    "forecaster = ExponentialSmoothing(trend=\"add\", seasonal=\"additive\", sp=12)\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The exponential smoothing of state space model can also be automated similar\n",
    " to the [ets](https://www.rdocumentation.org/packages/forecast/versions/8.13/topics/ets) function in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:07.947838Z",
     "iopub.status.busy": "2021-04-10T16:07:07.947189Z",
     "iopub.status.idle": "2021-04-10T16:07:10.206777Z",
     "shell.execute_reply": "2021-04-10T16:07:10.207270Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sktime.forecasting.ets import AutoETS\n",
    "\n",
    "forecaster = AutoETS(auto=True, sp=12, n_jobs=-1)\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common model is the ARIMA model. In `sktime`, we interface [`pmdarima`](https://github.com/alkaline-ml/pmdarima), a package for automatically selecting the best ARIMA model. This since searches over a number of possible model parametrisations, it may take a bit longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:10.214396Z",
     "iopub.status.busy": "2021-04-10T16:07:10.213787Z",
     "iopub.status.idle": "2021-04-10T16:07:13.628223Z",
     "shell.execute_reply": "2021-04-10T16:07:13.628556Z"
    }
   },
   "outputs": [],
   "source": [
    "forecaster = AutoARIMA(sp=12, suppress_warnings=True)\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single ARIMA model can also be manually configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:13.636135Z",
     "iopub.status.busy": "2021-04-10T16:07:13.635590Z",
     "iopub.status.idle": "2021-04-10T16:07:13.878516Z",
     "shell.execute_reply": "2021-04-10T16:07:13.879003Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forecaster = ARIMA(\n",
    "    order=(1, 1, 0), seasonal_order=(0, 1, 0, 12), suppress_warnings=True\n",
    ")\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BATS and TBATS are two other time series forecasting algorithms that are contained in `sktime` by means of wrapping the package [`tbats`](https://github.com/intive-DataScience/tbats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:13.883092Z",
     "iopub.status.busy": "2021-04-10T16:07:13.882587Z",
     "iopub.status.idle": "2021-04-10T16:07:21.598371Z",
     "shell.execute_reply": "2021-04-10T16:07:21.598869Z"
    }
   },
   "outputs": [],
   "source": [
    "from sktime.forecasting.bats import BATS\n",
    "\n",
    "forecaster = BATS(sp=12, use_trend=True, use_box_cox=False)\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:21.603008Z",
     "iopub.status.busy": "2021-04-10T16:07:21.602368Z",
     "iopub.status.idle": "2021-04-10T16:07:34.684002Z",
     "shell.execute_reply": "2021-04-10T16:07:34.684539Z"
    }
   },
   "outputs": [],
   "source": [
    "from sktime.forecasting.tbats import TBATS\n",
    "\n",
    "forecaster = TBATS(sp=12, use_trend=True, use_box_cox=False)\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sktime` also provides an interface to [`fbprophet`](https://github.com/facebook/prophet) by Facebook. Please note that `fbprophet` is strongly related to data with a time stamp of type `pd.DatetimeIndex`, so we have to convert the index type first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:34.689856Z",
     "iopub.status.busy": "2021-04-10T16:07:34.689346Z",
     "iopub.status.idle": "2021-04-10T16:07:34.691275Z",
     "shell.execute_reply": "2021-04-10T16:07:34.691758Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert index to pd.DatetimeIndex\n",
    "z = y.copy()\n",
    "z = z.to_timestamp(freq=\"M\")\n",
    "z_train, z_test = temporal_train_test_split(z, test_size=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:34.695861Z",
     "iopub.status.busy": "2021-04-10T16:07:34.695354Z",
     "iopub.status.idle": "2021-04-10T16:07:36.244503Z",
     "shell.execute_reply": "2021-04-10T16:07:36.245099Z"
    }
   },
   "outputs": [],
   "source": [
    "from sktime.forecasting.fbprophet import Prophet\n",
    "\n",
    "forecaster = Prophet(\n",
    "    seasonality_mode=\"multiplicative\",\n",
    "    n_changepoints=int(len(y_train) / 12),\n",
    "    add_country_holidays={\"country_name\": \"Germany\"},\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=False,\n",
    "    daily_seasonality=False,\n",
    ")\n",
    "forecaster.fit(z_train)\n",
    "y_pred = forecaster.predict(fh.to_relative(cutoff=y_train.index[-1]))\n",
    "\n",
    "y_pred.index = y_test.index\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composite model building\n",
    "\n",
    "`sktime` provides a modular API for composite model building for forecasting.\n",
    "\n",
    "### Ensembling\n",
    "Like `scikit-learn`, `sktime` provides a meta-forecaster to ensemble multiple forecasting algorithms. For example, we can combine different variants of exponential smoothing as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:36.322267Z",
     "iopub.status.busy": "2021-04-10T16:07:36.287424Z",
     "iopub.status.idle": "2021-04-10T16:07:36.486587Z",
     "shell.execute_reply": "2021-04-10T16:07:36.487094Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ses = ExponentialSmoothing(sp=12)\n",
    "holt = ExponentialSmoothing(trend=\"add\", damped_trend=False, sp=12)\n",
    "damped = ExponentialSmoothing(trend=\"add\", damped_trend=True, sp=12)\n",
    "\n",
    "forecaster = EnsembleForecaster(\n",
    "    [\n",
    "        (\"ses\", ses),\n",
    "        (\"holt\", holt),\n",
    "        (\"damped\", damped),\n",
    "    ]\n",
    ")\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning\n",
    "In `make_reduction`, both the `window_length` and `strategy` arguments are\n",
    "hyper-parameters which we may want to optimise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:36.557083Z",
     "iopub.status.busy": "2021-04-10T16:07:36.495720Z",
     "iopub.status.idle": "2021-04-10T16:07:37.096548Z",
     "shell.execute_reply": "2021-04-10T16:07:37.097150Z"
    }
   },
   "outputs": [],
   "source": [
    "forecaster = make_reduction(regressor, window_length=15, strategy=\"recursive\")\n",
    "param_grid = {\"window_length\": [5, 10, 15]}\n",
    "\n",
    "# We fit the forecaster on the initial window, and then use temporal\n",
    "# cross-validation to find the optimal parameter.\n",
    "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.8), window_length=20)\n",
    "gscv = ForecastingGridSearchCV(\n",
    "    forecaster, strategy=\"refit\", cv=cv, param_grid=param_grid\n",
    ")\n",
    "gscv.fit(y_train)\n",
    "y_pred = gscv.predict(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:37.120099Z",
     "iopub.status.busy": "2021-04-10T16:07:37.100367Z",
     "iopub.status.idle": "2021-04-10T16:07:37.372802Z",
     "shell.execute_reply": "2021-04-10T16:07:37.372246Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:37.375928Z",
     "iopub.status.busy": "2021-04-10T16:07:37.375391Z",
     "iopub.status.idle": "2021-04-10T16:07:37.377362Z",
     "shell.execute_reply": "2021-04-10T16:07:37.377899Z"
    }
   },
   "outputs": [],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning of wrapped regressor\n",
    "Using scikit-learn's `GridSearchCV`, we can tune regressors imported from scikit-learn, in addition to tuning `window_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:37.422479Z",
     "iopub.status.busy": "2021-04-10T16:07:37.416283Z",
     "iopub.status.idle": "2021-04-10T16:11:08.746794Z",
     "shell.execute_reply": "2021-04-10T16:11:08.747414Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# tuning the 'n_estimator' hyperparameter of RandomForestRegressor from scikit-learn\n",
    "regressor_param_grid = {\"n_estimators\": [100, 200, 300]}\n",
    "forecaster_param_grid = {\"window_length\": [7, 12, 15]}\n",
    "\n",
    "# create a tunnable regressor with GridSearchCV\n",
    "regressor = GridSearchCV(RandomForestRegressor(), param_grid=regressor_param_grid)\n",
    "forecaster = make_reduction(\n",
    "    regressor, scitype=\"tabular-regressor\", strategy=\"recursive\"\n",
    ")\n",
    "\n",
    "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.8), window_length=30)\n",
    "gscv = ForecastingGridSearchCV(forecaster, cv=cv, param_grid=forecaster_param_grid)\n",
    "\n",
    "gscv.fit(y_train)\n",
    "y_pred = gscv.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:11:08.750593Z",
     "iopub.status.busy": "2021-04-10T16:11:08.750113Z",
     "iopub.status.idle": "2021-04-10T16:11:08.751762Z",
     "shell.execute_reply": "2021-04-10T16:11:08.752258Z"
    }
   },
   "outputs": [],
   "source": [
    "print(gscv.best_params_, gscv.best_forecaster_.estimator_.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access performance on a particular metric during tuning, we can use the `scoring` argument of `ForecastingGridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:11:08.790482Z",
     "iopub.status.busy": "2021-04-10T16:11:08.789816Z",
     "iopub.status.idle": "2021-04-10T16:14:33.289515Z",
     "shell.execute_reply": "2021-04-10T16:14:33.290025Z"
    }
   },
   "outputs": [],
   "source": [
    "smape = MeanAbsolutePercentageError()\n",
    "gscv = ForecastingGridSearchCV(\n",
    "    forecaster, cv=cv, param_grid=forecaster_param_grid, scoring=smape\n",
    ")\n",
    "gscv.fit(y_train)\n",
    "pd.DataFrame(gscv.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic model selection using tuning plus multiplexer\n",
    "\n",
    "For model selection, 'MultiplexForecaster' is recommended to be used with 'ForecastingGridSearchCV'. Individually, 'MultiplexForecaster' takes different sktime forecasters wrapped in argument 'forecasters' and with the argument 'selected_forecaster', it selects which forecaster to fit when 'fit' is called. The real benefit of Multiplexer is achieved When 'MultiplexForecaster' is used in conjunction with 'ForecastingGridSearchCV'. The 'selected_forecaster' argument becomes an hyperparameter of 'MultiplexForecaster'. This way 'ForecastingGridSearchCV' provides a frame for MultiplexForecaster to switch between different forecasters to find the best performing one given a training data.\n",
    "\n",
    "The 'forecasters' argument of 'MultiplexForecaster' can take in any sktime forecaster. The functionality provided by 'MultiplexForecaster' can even be stretched by providing 'ForecastingGridSearchCV's with different estimators wrapped in 'forecasters'. This way, the process will first tune the hyperparameters of each forecaster and then return the best performing forecaster. This way, a pipeline of hyperparameter tunning and model selection can be processed by 'MultiplexForecaster'. Finally, 'MultiplexForecaster' can work with any tuner as well, since it is an sktime forecaster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:14:33.332255Z",
     "iopub.status.busy": "2021-04-10T16:14:33.310571Z",
     "iopub.status.idle": "2021-04-10T16:14:34.759567Z",
     "shell.execute_reply": "2021-04-10T16:14:34.760081Z"
    }
   },
   "outputs": [],
   "source": [
    "forecaster = MultiplexForecaster(\n",
    "    forecasters=[\n",
    "        (\"naive\", NaiveForecaster(strategy=\"last\")),\n",
    "        (\"ets\", ExponentialSmoothing(trend=\"add\", sp=12)),\n",
    "    ]\n",
    ")\n",
    "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.5), window_length=30)\n",
    "forecaster_param_grid = {\"selected_forecaster\": [\"ets\", \"naive\"]}\n",
    "gscv = ForecastingGridSearchCV(forecaster, cv=cv, param_grid=forecaster_param_grid)\n",
    "\n",
    "gscv.fit(y_train)\n",
    "y_pred = gscv.predict(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single update, you can use the `update` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:14:34.862037Z",
     "iopub.status.busy": "2021-04-10T16:14:34.861515Z",
     "iopub.status.idle": "2021-04-10T16:14:35.002694Z",
     "shell.execute_reply": "2021-04-10T16:14:35.003199Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:14:35.007827Z",
     "iopub.status.busy": "2021-04-10T16:14:35.007334Z",
     "iopub.status.idle": "2021-04-10T16:14:35.009284Z",
     "shell.execute_reply": "2021-04-10T16:14:35.009782Z"
    }
   },
   "outputs": [],
   "source": [
    "print(gscv.best_params_, \"\\n\", gscv.best_forecaster_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detrending\n",
    "Note that so far the reduction approach above does not take any seasonal or trend into account, but we can easily specify a pipeline which first detrends the data.\n",
    "\n",
    "`sktime` provides a generic detrender, a transformer which uses any forecaster and returns the in-sample residuals of the forecaster's predicted values. For example, to remove the linear trend of a time series, we can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:14:35.018479Z",
     "iopub.status.busy": "2021-04-10T16:14:35.014326Z",
     "iopub.status.idle": "2021-04-10T16:14:35.217803Z",
     "shell.execute_reply": "2021-04-10T16:14:35.218297Z"
    }
   },
   "outputs": [],
   "source": [
    "# liner detrending\n",
    "forecaster = PolynomialTrendForecaster(degree=1)\n",
    "transformer = Detrender(forecaster=forecaster)\n",
    "yt = transformer.fit_transform(y_train)\n",
    "\n",
    "# internally, the Detrender uses the in-sample predictions\n",
    "# of the PolynomialTrendForecaster\n",
    "forecaster = PolynomialTrendForecaster(degree=1)\n",
    "fh_ins = -np.arange(len(y_train))  # in-sample forecasting horizon\n",
    "y_pred = forecaster.fit(y_train).predict(fh=fh_ins)\n",
    "\n",
    "plot_series(y_train, y_pred, yt, labels=[\"y_train\", \"fitted linear trend\", \"residuals\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelining\n",
    "\n",
    "Let's use the detrender in a pipeline together with de-seasonalisation. Note that in forecasting, when we apply data transformations before fitting, we need to apply the inverse transformation to the predicted values. For this purpose, we provide the following pipeline class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:14:35.229259Z",
     "iopub.status.busy": "2021-04-10T16:14:35.226506Z",
     "iopub.status.idle": "2021-04-10T16:14:39.867659Z",
     "shell.execute_reply": "2021-04-10T16:14:39.868153Z"
    }
   },
   "outputs": [],
   "source": [
    "forecaster = TransformedTargetForecaster(\n",
    "    [\n",
    "        (\"deseasonalize\", Deseasonalizer(model=\"multiplicative\", sp=12)),\n",
    "        (\"detrend\", Detrender(forecaster=PolynomialTrendForecaster(degree=1))),\n",
    "        (\n",
    "            \"forecast\",\n",
    "            make_reduction(\n",
    "                regressor,\n",
    "                scitype=\"tabular-regressor\",\n",
    "                window_length=15,\n",
    "                strategy=\"recursive\",\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we could try again to optimise the hyper-parameters of components of the pipeline.\n",
    "\n",
    "Below we discuss two other aspects of forecasting: online learning, where we want to dynamically update forecasts as new data comes in, and prediction intervals, which allow us to quantify the uncertainty of our forecasts.\n",
    "\n",
    "## Online Forecasting\n",
    "\n",
    "For model evaluation, we sometimes want to evaluate multiple forecasts, using temporal cross-validation with a sliding window over the test data. For this purpose, we can leverage the forecasters from the `online_forecasting` module which use a composite forecaster, `PredictionWeightedEnsemble`, to keep track of the loss accumulated by each forecaster and create a prediction weighted by the predictions of the most \"accurate\" forecasters.\n",
    "\n",
    "Note that the forecasting task is changed: we make 35 predictions since we need the first prediction to help update the weights, we do not predict 36 steps ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:14:39.872044Z",
     "iopub.status.busy": "2021-04-10T16:14:39.871304Z",
     "iopub.status.idle": "2021-04-10T16:14:39.874814Z",
     "shell.execute_reply": "2021-04-10T16:14:39.875324Z"
    }
   },
   "outputs": [],
   "source": [
    "from sktime.forecasting.all import mean_squared_error\n",
    "from sktime.forecasting.online_learning import (\n",
    "    NormalHedgeEnsemble,\n",
    "    OnlineEnsembleForecaster,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to initialize a `PredictionWeightedEnsembler` that will keep track of the loss accumulated by each forecaster and define which loss function we would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:14:39.878435Z",
     "iopub.status.busy": "2021-04-10T16:14:39.877913Z",
     "iopub.status.idle": "2021-04-10T16:14:39.879324Z",
     "shell.execute_reply": "2021-04-10T16:14:39.879979Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hedge_expert = NormalHedgeEnsemble(n_estimators=3, loss_func=mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can then create the forecaster by defining the individual forecasters and specifying the `PredictionWeightedEnsembler` we are using. Then by fitting our forecasters and performing updates and prediction with the `update_predict` function, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:14:39.923246Z",
     "iopub.status.busy": "2021-04-10T16:14:39.920259Z",
     "iopub.status.idle": "2021-04-10T16:14:40.917504Z",
     "shell.execute_reply": "2021-04-10T16:14:40.918060Z"
    }
   },
   "outputs": [],
   "source": [
    "forecaster = OnlineEnsembleForecaster(\n",
    "    [\n",
    "        (\"ses\", ses),\n",
    "        (\"holt\", holt),\n",
    "        (\"damped\", damped),\n",
    "    ],\n",
    "    ensemble_algorithm=hedge_expert,\n",
    ")\n",
    "\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.update_predict(y_test)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_test[1:], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction intervals\n",
    "So far, we've only looked at point forecasts. In many cases, we're also interested in prediction intervals. `sktime`'s interface support prediction intervals, but we haven't implemented them for all algorithms yet.\n",
    "\n",
    "Here, we use the Theta forecasting algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:14:40.934978Z",
     "iopub.status.busy": "2021-04-10T16:14:40.934373Z",
     "iopub.status.idle": "2021-04-10T16:14:40.937008Z",
     "shell.execute_reply": "2021-04-10T16:14:40.937503Z"
    }
   },
   "outputs": [],
   "source": [
    "forecaster = ThetaForecaster(sp=12)\n",
    "forecaster.fit(y_train)\n",
    "alpha = 0.05  # 95% prediction intervals\n",
    "y_pred, pred_ints = forecaster.predict(fh, return_pred_int=True, alpha=alpha)\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:14:40.970332Z",
     "iopub.status.busy": "2021-04-10T16:14:40.962229Z",
     "iopub.status.idle": "2021-04-10T16:14:41.157733Z",
     "shell.execute_reply": "2021-04-10T16:14:41.158242Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "ax.fill_between(\n",
    "    ax.get_lines()[-1].get_xdata(),\n",
    "    pred_ints[\"lower\"],\n",
    "    pred_ints[\"upper\"],\n",
    "    alpha=0.2,\n",
    "    color=ax.get_lines()[-1].get_c(),\n",
    "    label=f\"{1 - alpha}% prediction intervals\",\n",
    ")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation for forecasting (backtesting)\n",
    "In forecasting, we usually want to know how well a forecaster would have performed in the past. This goes beyond a simple train-test-split because we want to backtest multiple fit/updates on different data. A forecaster evaluation consists at least of...\n",
    "- `forecaster` that can also be a `ForecastingGridSearchCV` or `EnsembleForecaster`\n",
    "- `cv` of e.g. `ExpandingWindowSplitter` or `SlidingWindowSplitter`\n",
    "- `strategy` wether the forecaster should be always be refitted or just fitted once and then updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:14:41.175611Z",
     "iopub.status.busy": "2021-04-10T16:14:41.172625Z",
     "iopub.status.idle": "2021-04-10T16:15:23.924289Z",
     "shell.execute_reply": "2021-04-10T16:15:23.925010Z"
    }
   },
   "outputs": [],
   "source": [
    "forecaster = AutoARIMA(sp=12, suppress_warnings=True)\n",
    "cv = ExpandingWindowSplitter(\n",
    "    step_length=12, fh=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], initial_window=72\n",
    ")\n",
    "\n",
    "df = evaluate(forecaster=forecaster, y=y, cv=cv, strategy=\"refit\", return_data=True)\n",
    "df.iloc[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:15:24.049731Z",
     "iopub.status.busy": "2021-04-10T16:15:23.930923Z",
     "iopub.status.idle": "2021-04-10T16:15:24.297592Z",
     "shell.execute_reply": "2021-04-10T16:15:24.298144Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualization of a forecaster evaluation\n",
    "fig, ax = plot_series(\n",
    "    y,\n",
    "    df[\"y_pred\"].iloc[0],\n",
    "    df[\"y_pred\"].iloc[1],\n",
    "    df[\"y_pred\"].iloc[2],\n",
    "    df[\"y_pred\"].iloc[3],\n",
    "    df[\"y_pred\"].iloc[4],\n",
    "    df[\"y_pred\"].iloc[5],\n",
    "    markers=[\"o\", \"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "    labels=[\"y_true\"] + [\"y_pred (Backtest \" + str(x) + \")\" for x in range(6)],\n",
    ")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "As we have seen, in order to make forecasts, we need to first specify (or build) a model, then fit it to the training data, and finally call predict to generate forecasts for the given forecasting horizon.\n",
    "\n",
    "* `sktime` comes with several forecasting algorithms (or forecasters) and tools for composite model building. All forecaster share a common interface. Forecasters are trained on a single series of data and make forecasts for the provided forecasting horizon.\n",
    "\n",
    "* `sktime` has a number of statistical forecasting algorithms, based on implementations in statsmodels. For example, to use exponential smoothing with an additive trend component and multiplicative seasonality, we can write the following.\n",
    "\n",
    "\n",
    "## Useful resources\n",
    "* For more details, take a look at [our paper on forecasting with sktime](https://arxiv.org/abs/2005.08067) in which we discuss the forecasting API in more detail and use it to replicate and extend the M4 study.\n",
    "* For a good introduction to forecasting, see [Hyndman, Rob J., and George Athanasopoulos. Forecasting: principles and practice. OTexts, 2018](https://otexts.com/fpp2/).\n",
    "* For comparative benchmarking studies/forecasting competitions, see the [M4 competition](https://www.sciencedirect.com/science/article/pii/S0169207019301128) and the currently running [M5 competition](https://www.kaggle.com/c/m5-forecasting-accuracy/overview)."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0bc250fec99d1b72e5bb23d9fb06e1f1ac90e860438a1535c061277d2caf5ebfc",
   "display_name": "Python 3.7.10 64-bit ('sktime': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}