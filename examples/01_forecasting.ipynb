{
 "cells": [
  {
   "source": [
    "**Set-up instructions:** this notebook give a tutorial on the forecasting learning task supported by `sktime`.\n",
    "On binder, this should run out-of-the-box.\n",
    "\n",
    "To run this notebook as intended, ensure that `sktime` with basic dependency requirements is installed in your python environment.\n",
    "\n",
    "To run this notebook with a local development version of sktime, either uncomment and run the below, or `pip install -e` a local clone of the `sktime` `main` branch."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from os import sys\n",
    "# sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting with sktime\n",
    "\n",
    "In forecasting, past data is used to make temporal forward predictions of a time series. This is notably different from tabular prediction tasks supported by `scikit-learn` and similar libraries.\n",
    "\n",
    "\n",
    "<img src=\"img/forecasting.png\" width=750 />\n",
    "\n",
    "`sktime` provides a common, `scikit-learn`-like interface to a variety of classical and ML-style forecasting algorithms, together with tools for building pipelines and composite machine learning models, including temporal tuning schemes, or reductions such as walk-forward application of `scikit-learn` regressors.\n",
    "\n",
    "**Section 1** provides an overview of common forecasting workflows supported by `sktime`.\n",
    "\n",
    "**Section 2** discusses the families of forecasters available in `sktime`.\n",
    "\n",
    "**Section 3** discusses advanced composition patterns, including pipeline building, reduction, tuning, ensembling, and autoML.\n",
    "\n",
    "**Section 4** gives an introduction to how to write custom estimators compliant with the `sktime` interface.\n",
    "\n",
    "Further references:\n",
    "* for further details on how forecasting is different from supervised prediction Ã  la `scikit-learn`, and pitfalls of misdiagnosing forecasting as supervised prediction, have a look at [this notebook](./01a_forecasting_sklearn.ipynb)\n",
    "* for a scientific reference, take a look at [our paper on forecasting with sktime](https://arxiv.org/abs/2005.08067) in which we discuss `sktime`'s forecasting module in more detail and use it to replicate and extend the M4 study."
   ]
  },
  {
   "source": [
    "#### package imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic forecasting workflows"
   ]
  },
  {
   "source": [
    "This section explains the basic forecasting workflows, and key interface points for it.\n",
    "\n",
    "We cover the following three workflows:\n",
    "\n",
    "* basic deployment workflow: batch fitting and forecasting\n",
    "* basic evaluation workflow: evaluating a batch of forecasts against ground truth observations\n",
    "* advanced deployment workflow: fitting and rolling updates/forecasts\n",
    "* advanced evaluation worfklow: using rolling forecast splits and computing split-wise and aggregate errors, including common back-testing schemes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data container format\n",
    "\n",
    "All workflows make common assumptions on the input data format.\n",
    "\n",
    "`sktime` uses `pandas` for representing time series:\n",
    "\n",
    "* `pd.Series` for univariate time series and sequences\n",
    "* `pd.DataFrame` for multivariate time series and sequences\n",
    "\n",
    "The `Series.index` and `DataFrame.index` are used for representing the time series or sequence index. `sktime` supports pandas integer, period and timestamp indices.\n",
    "\n",
    "NOTE: at current time (v0.6x), forecasting of multivariate time seres is not a stable functionality, this is a priority roadmap item. Multivariate exogeneous time series are part of stable functionality."
   ]
  },
  {
   "source": [
    "**Example:** as the running example in this tutorial, we use a textbook data set, the Box-Jenkins airline data set, which consists of the number of monthly totals of international airline passengers, from 1949 - 1960. Values are in thousands. See \"Makridakis, Wheelwright and Hyndman (1998) Forecasting: methods and applications\", exercises sections 2 and 3."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.utils.plotting import plot_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:05.849641Z",
     "iopub.status.busy": "2021-04-10T16:07:05.849188Z",
     "iopub.status.idle": "2021-04-10T16:07:06.049023Z",
     "shell.execute_reply": "2021-04-10T16:07:06.049499Z"
    }
   },
   "outputs": [],
   "source": [
    "y = load_airline()\n",
    "\n",
    "# plotting for visualization\n",
    "plot_series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, users are expected to use the in-built loading functionality of `pandas` and `pandas`-compatible packages to load data sets for forecasting, such as `read_csv` or the `Series` or `DataFrame` constructors if data is available in another in-memory format, e.g., `numpy.array`.\n",
    "\n",
    "`sktime` forecasters may accept input in `pandas`-adjacent formats, but will produce outputs in, and attempt to coerce inputs to, `pandas` formats.\n",
    "\n",
    "NOTE: if your favourite format is not properly converted or coerced, kindly consider to contribute that functionality to `sktime`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Basic deployment workflow - batch fitting and forecasting"
   ]
  },
  {
   "source": [
    "The simplest use case workflow is batch fitting and forecasting, i.e., fitting a forecasting model to one batch of past data, then asking for forecasts at time point in the future.\n",
    "\n",
    "The steps in this workflow are as follows:\n",
    "\n",
    "1. preparation of the data\n",
    "2. specification of the time points for which forecasts are requested. This uses a `numpy.array` or the `ForecastingHorizon` object.\n",
    "3. specification and instantiation of the forecaster. This follows a `scikit-learn`-like syntax; forecaster objects follow the familiar `scikit-learn` `BaseEstimator` interface.\n",
    "4. fitting the forecaster to the data, using the forecaster's `fit` method\n",
    "5. making a forecast, using the forecaster's `predict` method\n",
    "\n",
    "The below first outlines the vanilla variant of the basic deployment workflow, step-by-step.\n",
    "\n",
    "At the end, one-cell workflows are provided, with common deviations from the pattern (Sections 1.2.1 and following)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### step 1 - preparation of the data\n",
    "\n",
    "as discussed in Section 1.1, the data is assumed to be in `pd.Series` or `pd.DataFrame` format."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.utils.plotting import plot_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the example, we use the airline data set.\n",
    "y = load_airline()\n",
    "plot_series(y)"
   ]
  },
  {
   "source": [
    "#### step 2 - specifying the forecasting horizon"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to specify the forecasting horizon and pass that to our forecasting algorithm.\n",
    "\n",
    "There are two main ways:\n",
    "\n",
    "* using a `numpy.array` of integers. This assumes either integer index or periodic index (`PeriodIndex`) in the time series; the integer indicates the number of time points or periods ahead we want to make a forecast for. E.g., `1` means forecast the next period, `2` the second next period, and so on.\n",
    "* using a `ForecastingHorizon` object. This can be used to define forecast horizons, using any supported index type as an argument. No periodic index is assumed.\n",
    "\n",
    "Forecasting horizons can be absolute, i.e., referencing specific time points in the future, or relative, i.e., referencing time differences to the present. As a default, the present is that latest time point seen in any `y` passed to the forecaster.\n",
    "\n",
    "`numpy.array` based forecasting horizons are always relative; `ForecastingHorizon` objects can be both relative and absolute. In particular, absolute forecasting horizons can only be specified using `ForecastingHorizon`."
   ]
  },
  {
   "source": [
    "##### using a numpy forecasting horizon"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:06.222860Z",
     "iopub.status.busy": "2021-04-10T16:07:06.222322Z",
     "iopub.status.idle": "2021-04-10T16:07:06.224682Z",
     "shell.execute_reply": "2021-04-10T16:07:06.225165Z"
    }
   },
   "outputs": [],
   "source": [
    "fh = np.arange(1, 37)\n",
    "fh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will ask for monthly predictions for the next three years, since the original series period is 1 month.\n",
    "In another example, to predict only the second and fifth month ahead, one could write:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "fh = np.array([2, 5])  # 2nd and 5th step ahead\n",
    "```"
   ]
  },
  {
   "source": [
    "##### Using a `ForecastingHorizon` based forecasting horizon\n",
    "\n",
    "The `ForecastingHorizon` object takes absolute indices as input, but considers the input absolute or relative depending on the `is_relative` flag.\n",
    "\n",
    "`ForecastingHorizon` will automatically assume a relative horizon if temporal difference types from `pandas` are passed; if value types from `pandas` are passed, it will assume an absolute horizon.\n",
    "\n",
    "To define an absolute `ForecastingHorizon` in our example:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.base import ForecastingHorizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:06.229051Z",
     "iopub.status.busy": "2021-04-10T16:07:06.228401Z",
     "iopub.status.idle": "2021-04-10T16:07:06.230685Z",
     "shell.execute_reply": "2021-04-10T16:07:06.231173Z"
    }
   },
   "outputs": [],
   "source": [
    "fh = ForecastingHorizon(pd.PeriodIndex(pd.date_range('1961-01', periods=36, freq='M')), is_relative=False)\n",
    "fh"
   ]
  },
  {
   "source": [
    "`ForecastingHorizon`-s can be converted from relative to absolute and back via the `to_relative` and `to_absolute` methods. Both of these conversions require a compatible `cutoff` to be passed:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = pd.Period('1960-12', freq='M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh.to_relative(cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh.to_absolute(cutoff)"
   ]
  },
  {
   "source": [
    "#### step 3 - specifying the forecasting algorithm\n",
    "\n",
    "To make forecasts, a forecasting algorithm needs to be specified. This is done using a `scikit-learn`-like interface. Most importantly, all `sktime` forecasters follow the same interface, so the preceding and remaining steps are the same, no matter which forecaster is being chosen.\n",
    "\n",
    "For this example, we choose the naive forecasting method of predicting the last seen value. More complex specifications are possible, using pipeline and reduction construction syntax; this will be covered later in Section 2."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.naive import NaiveForecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = NaiveForecaster(strategy=\"last\")"
   ]
  },
  {
   "source": [
    "#### step 4 - fitting the forecaster to the seen data\n",
    "\n",
    "Now the forecaster needs to be fitted to the seen data:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.fit(y)"
   ]
  },
  {
   "source": [
    "#### step 5 - requesting forecasts\n",
    "\n",
    "Finally, we request forecasts for the specified forecasting horizon. This needs to be done after fitting the forecaster:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forecaster.predict(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting predictions and past data\n",
    "plot_series(y, y_pred, labels=[\"y\", \"y_pred\"])"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 1.2.1 the basic deployment workflow in a nutshell\n",
    "\n",
    "for convenience, we present the basic deployment workflow in one cell.\n",
    "This uses the same data, but different forecaster: predicting the latest value observed in the same month."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.naive import NaiveForecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: data specification\n",
    "y = load_airline()\n",
    "\n",
    "# step 2: specifying forecasting horizon\n",
    "fh = np.arange(1, 37)\n",
    "\n",
    "# step 3: specifying the forecasting algorithm\n",
    "forecaster = NaiveForecaster(strategy=\"last\", sp=12)\n",
    "\n",
    "# step 4: fitting the forecaster\n",
    "forecaster.fit(y)\n",
    "\n",
    "# step 5: querying predictions\n",
    "y_pred = forecaster.predict(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: plotting predictions and past data\n",
    "plot_series(y, y_pred, labels=[\"y\", \"y_pred\"])"
   ]
  },
  {
   "source": [
    "#### 1.2.2 forecasters that require the horizon already in `fit`\n",
    "\n",
    "Some forecasters need the forecasting horizon provided already in `fit`. Such forecasters will produce informative error messages when it is not passed in `fit`. All forecaster will remember the horizon when already passed in `fit` for prediction. The modified workflow to allow for such forecasters in addition is as follows:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: data specification\n",
    "y = load_airline()\n",
    "\n",
    "# step 2: specifying forecasting horizon\n",
    "fh = np.arange(1, 37)\n",
    "\n",
    "# step 3: specifying the forecasting algorithm\n",
    "forecaster = NaiveForecaster(strategy=\"last\", sp=12)\n",
    "\n",
    "# step 4: fitting the forecaster\n",
    "forecaster.fit(y, fh=fh)\n",
    "\n",
    "# step 5: querying predictions\n",
    "y_pred = forecaster.predict()"
   ]
  },
  {
   "source": [
    "#### 1.2.3 forecasters that can make use of exogeneous data\n",
    "\n",
    "Many forecasters can make use of exogeneous time series, i.e., other time series that are not forecast, but are useful for forecasting `y`. Exogeneous time series are always passed as an `X` argument, in `fit`, `predict`, and other methods (see below). Exogeneous time series should always be passed as `pandas.DataFrames`. Most forecasters that can deal with exogeneous time series will assume that the time indices of `X` passed to `fit` are a super-set of the time indices in `y` passed to `fit`; and that the time indices of `X` passed to `predict` are a super-set of time indices in `fh`, although this is not a general interface restriction. Forecasters that do not make use of exogeneous time series still accept the argument (and do not use it internally).\n",
    "\n",
    "The general workflow for passing exogeneous data is as follows:"
   ],
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:06.475031Z",
     "iopub.status.busy": "2021-04-10T16:07:06.473831Z",
     "iopub.status.idle": "2021-04-10T16:07:06.613175Z",
     "shell.execute_reply": "2021-04-10T16:07:06.613700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: data specification\n",
    "y = load_airline()\n",
    "# we create some dummy exogeneous data\n",
    "X = pd.DataFrame(index=y.index)\n",
    "\n",
    "# step 2: specifying forecasting horizon\n",
    "fh = np.arange(1, 37)\n",
    "\n",
    "# step 3: specifying the forecasting algorithm\n",
    "forecaster = NaiveForecaster(strategy=\"last\", sp=12)\n",
    "\n",
    "# step 4: fitting the forecaster\n",
    "forecaster.fit(y, X=X, fh=fh)\n",
    "\n",
    "# step 5: querying predictions\n",
    "y_pred = forecaster.predict(X=X)"
   ]
  },
  {
   "source": [
    "NOTE: as in workflows 1.2.1 and 1.2.2, some forecasters that use exogeneous variables may also require the forecasting horizon only in `predict`. Such forecasters may also be called with steps 4 and 5 being\n",
    "```python\n",
    "forecaster.fit(y, X=X)\n",
    "y_pred = forecaster.predict(fh=fh, X=X)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1.3 basic evaluation workflow - evaluating a batch of forecasts against ground truth observations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "It is good practice to evaluate statistical performance of a forecaster before deploying it, and regularly re-evaluate performance if in continuous deployment. The evaluation workflow for the basic batch forecasting task, as solved by the workflow in Section 1.2, consists of comparing batch forecasts with actuals. This is sometimes called (batch-wise) backtesting.\n",
    "\n",
    "The basic evaluation workflow is as follows:\n",
    "\n",
    "1. splitting a representatively chosen historical series into a temporal training and test set. The test set should be temporally in the future of the training set.\n",
    "2. obtaining batch forecasts, as in Section 1.2, by fitting a forecaster to the training set, and querying predictions for the test set\n",
    "3. specifying a quantitative performance metric to compare the actual test set against predictions\n",
    "4. computing the quantitative performance on the test set\n",
    "5. testing whether this performance is statistically better than a chosen baseline performance\n",
    "\n",
    "NOTE: step 5 (testing) is currently not supported in `sktime`, but is on the development roadmap. For the time being, it is advised to use custom implementations of appropriate methods (e.g., Diebold-Mariano test; stationary confidence intervals).\n",
    "\n",
    "NOTE: note that this evaluation set-up determines how well a given algorithm would have performed on past data. Results are only insofar representative as future performance can be assumed to mirror past performance. This can be argued under certain assumptions (e.g., stationarity), but will in general be false. Monitoring of forecasting performance is hence advised in case an algorithm is applied multiple times."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Example:** In the example, we will us the same airline data as in Section 1.2. But, instead of predicting the next 3 years, we hold out the last 3 years of the airline data (below: `y_test`), and see how the forecaster would have performed three years ago, when asked to forecast the most recent 3 years (below: `y_pred`), from the years before (below: `y_train`). \"how\" is measured by a quantitative performance metric (below: `mean_absolute_percentage_error`). This is then considered as an indication of how well the forecaster would perform in the coming 3 years (what was done in Section 1.2). This may or may not be a stretch depending on statistical assumptions and data properties (caution: it often is a stretch - past performance is in general not indicative of future performance)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### step 1 - splitting a historical data set in to a temporal train and test batch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_selection import temporal_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = load_airline()\n",
    "y_train, y_test = temporal_train_test_split(y, test_size=36)\n",
    "# we will try to forecast y_test from y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting for illustration\n",
    "plot_series(y_train, y_test, labels=[\"y_train\", \"y_test\"])\n",
    "print(y_train.shape[0], y_test.shape[0])"
   ]
  },
  {
   "source": [
    "#### step 2 - querying predictions for y_test from y_train\n",
    "\n",
    "This is almost verbatim the workflow in Section 1.2, using `y_train` to predict the indices of `y_test`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can simply take the indices from `y_test` where they already are stored\n",
    "fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
    "\n",
    "forecaster = NaiveForecaster(strategy=\"last\", sp=12)\n",
    "\n",
    "forecaster.fit(y_train)\n",
    "\n",
    "# y_pred will contain the predictions\n",
    "y_pred = forecaster.predict(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting for illustration\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])"
   ]
  },
  {
   "source": [
    "#### steps 3 and 4 - specifying a forecasting metric, evaluating on the test set\n",
    "\n",
    "The next step is to specify a forecasting metric. These are functions that return a number when input with prediction and actual series. They are different from `sklearn` metrics in that they accept series with indices rather than `np.array`s. Forecasting metrics can be invoked in two ways:\n",
    "\n",
    "* using the lean function interface, e.g., `mean_absolute_percentage_error` which is a python function `(y_true : pd.Series, y_pred : pd.Series) -> float`\n",
    "* using the composable class interface, e.g., `MeanAbsolutePercentageError`, which is a python class, callable with the same signature\n",
    "\n",
    "Casual users may opt to use the function interface. The class interface supports advanced use cases, such as parameter modification, custom metric composition, tuning over metric parameters (not covered in this tutorial)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 1: using the lean function interface\n",
    "mean_absolute_percentage_error(y_test, y_pred)\n",
    "# note: the FIRST argument is the ground truth, the SECOND argument are the forecasts\n",
    "#       the order matters for most metrics in general"
   ]
  },
  {
   "source": [
    "To properly interpret numbers like this, it is useful to understand properties of the metric in question (e.g., lower is better), and to compare against suitable baselines and contender algorithms (see step 5)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import MeanAbsolutePercentageError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 2: using the composable class interface\n",
    "mape = MeanAbsolutePercentageError(symmetric = False)\n",
    "# the class interface allows to easily construct variants of the MAPE, e.g., the non-symmetric verion\n",
    "# it also allows for inspection of metric properties, e.g., are higher values better (answer: no)?\n",
    "mape.greater_is_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation works exactly like in option 2, but with the instantiated object\n",
    "mape(y_test, y_pred)"
   ]
  },
  {
   "source": [
    "NOTE: some metrics, such as `mean_absolute_scaled_error`, also require the training set for evaluation. In this case, the training set should be passed as a `y_train` argument. Refer to the API reference on individual metrics.\n",
    "\n",
    "NOTE: the workflow is the same for forecasters that make use of exogeneous data - no `X` is passed to the metrics."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### step 5 - testing performance against benchmarks\n",
    "\n",
    "In general, forecast performances should be quantitatively tested against benchmark performances.\n",
    "\n",
    "Currently (`sktime` v0.6x), this is a roadmap development item. Contributions are very welcome."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 1.3.1 the basic batch forecast evaluation workflow in a nutshell - function metric interface\n",
    "\n",
    "For convenience, we present the basic batch forecast evaluation workflow in one cell.\n",
    "This cell is using the lean function metric interface."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: splitting historical data\n",
    "y = load_airline()\n",
    "y_train, y_test = temporal_train_test_split(y, test_size=36)\n",
    "\n",
    "# step 2: running the basic forecasting workflow\n",
    "fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
    "forecaster = NaiveForecaster(strategy=\"last\", sp=12)\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "\n",
    "# step 3: specifying the evaluation metric and\n",
    "# step 4: computing the forecast performance\n",
    "mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "# step 5: testing forecast performance against baseline\n",
    "# under development"
   ]
  },
  {
   "source": [
    "#### 1.3.2 the basic batch forecast evaluation workflow in a nutshell - metric class interface\n",
    "\n",
    "For convenience, we present the basic batch forecast evaluation workflow in one cell.\n",
    "This cell is using the advanced class specification interface for metrics."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.performance_metrics.forecasting import MeanAbsolutePercentageError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: splitting historical data\n",
    "y = load_airline()\n",
    "y_train, y_test = temporal_train_test_split(y, test_size=36)\n",
    "\n",
    "# step 2: running the basic forecasting workflow\n",
    "fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
    "forecaster = NaiveForecaster(strategy=\"last\", sp=12)\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "\n",
    "# step 3: specifying the evaluation metric\n",
    "mape = MeanAbsolutePercentageError(symmetric = False)\n",
    "# if function interface is used, just use the function directly in step 4\n",
    "\n",
    "# step 4: computing the forecast performance\n",
    "mape(y_test, y_pred)\n",
    "\n",
    "# step 5: testing forecast performance against baseline\n",
    "# under development"
   ]
  },
  {
   "source": [
    "### 1.4 advanced deployment workflow: rolling updates & forecasts"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "TODO"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1.5 advanced evaluation worfklow: rolling re-sampling and aggregate errors, rolling back-testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "TODO"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Model evaluation for forecasting (backtesting)\n",
    "In forecasting, we usually want to know how well a forecaster would have performed in the past. This goes beyond a simple train-test-split because we want to backtest multiple fit/updates on different data. A forecaster evaluation consists at least of...\n",
    "- `forecaster` that can also be a `ForecastingGridSearchCV` or `EnsembleForecaster`\n",
    "- `cv` of e.g. `ExpandingWindowSplitter` or `SlidingWindowSplitter`\n",
    "- `strategy` wether the forecaster should be always be refitted or just fitted once and then updated\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = AutoARIMA(sp=12, suppress_warnings=True)\r\n",
    "cv = ExpandingWindowSplitter(\r\n",
    "    step_length=12, fh=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], initial_window=72\r\n",
    ")\r\n",
    "\r\n",
    "df = evaluate(forecaster=forecaster, y=y, cv=cv, strategy=\"refit\", return_data=True)\r\n",
    "df.iloc[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of a forecaster evaluation\n",
    "fig, ax = plot_series(\n",
    "    y,\n",
    "    df[\"y_pred\"].iloc[0],\n",
    "    df[\"y_pred\"].iloc[1],\n",
    "    df[\"y_pred\"].iloc[2],\n",
    "    df[\"y_pred\"].iloc[3],\n",
    "    df[\"y_pred\"].iloc[4],\n",
    "    df[\"y_pred\"].iloc[5],\n",
    "    markers=[\"o\", \"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "    labels=[\"y_true\"] + [\"y_pred (Backtest \" + str(x) + \")\" for x in range(6)],\n",
    ")\n",
    "ax.legend();"
   ]
  },
  {
   "source": [
    "## 2. Forecasters in `sktime` - main families\n",
    "\n",
    "`sktime` supports a number of commonly used forecasters, many of them interfaced from state-of-art forecasting packages. All forecasters are available under the unified `sktime` interface.\n",
    "\n",
    "The main classes that are currently stably supported are:\n",
    "\n",
    "* `ExponentialSmoothing`, `ThetaForecaster`, and `autoETS` from `statsmodels`\n",
    "* `ARIMA` and `autoARIMA` from `pmdarima`\n",
    "* `BATS` and `TBATS` from `tbats`\n",
    "* `PolynomialTrend` for forecasting polynomial trends\n",
    "* `Prophet` which interfaces Facebook `prophet`\n",
    "\n",
    "For illustration, all estimators below will be presented on the basic forecasting workflow - though they also support the advanced forecasting and evaluation workflows under the unified `sktime` interface (see Section 1).\n",
    "\n",
    "For use in the other workflows, simply replace the \"forecaster specification block\" (\"`forecaster=`\") by the forecaster specification block in the examples presented below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports necessary for this chapter\n",
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.utils.plotting import plot_series\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error\n",
    "# data loading for illustration (see section 1 for explanation)\n",
    "y = load_airline()\n",
    "y_train, y_test = temporal_train_test_split(y, test_size=36)\n",
    "fh = ForecastingHorizon(y_test.index, is_relative=False)"
   ]
  },
  {
   "source": [
    "### 2.1 exponential smoothing, theta forecaster, autoETS from `statsmodels`\n",
    "\n",
    "`sktime` interfaces a number of statistical forecasting algorithms from `statsmodels`: exponential smoothing, theta, and aut-ETS."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "For example, to use exponential smoothing with an additive trend component and multiplicative seasonality on the airline data set, we can write the following.\n",
    "\n",
    "Note that since this is monthly data, a good choic for seasonal periodicity (sp) is 12 (= hypothesized periodicity of a year)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.exp_smoothing import ExponentialSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ExponentialSmoothing(trend=\"add\", seasonal=\"additive\", sp=12)\n",
    "\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "source": [
    "The exponential smoothing of state space model can also be automated similar\n",
    " to the [ets](https://www.rdocumentation.org/packages/forecast/versions/8.13/topics/ets) function in R. This is implemented in the `AutoETS` forecaster."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.ets import AutoETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = AutoETS(auto=True, sp=12, n_jobs=-1)\n",
    "\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### todo: explain Theta; explain how to get theta-lines"
   ]
  },
  {
   "source": [
    "### 2.2 ARIMA and autoARIMA\n",
    "\n",
    "`sktime` interfaces `pmdarima` for its ARIMA class models.\n",
    "For a classical ARIMA model with set parameters, use the `ARIMA` forecaster:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.arima import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ARIMA(\n",
    "    order=(1, 1, 0), seasonal_order=(0, 1, 0, 12), suppress_warnings=True\n",
    ")\n",
    "\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "source": [
    "`AutoARIMA` is an automatically tuned `ARIMA` variant that obatins the optimal pdq parameters automatically:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.arima import AutoARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = AutoARIMA(sp=12, suppress_warnings=True)\n",
    "\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to obtain the fitted parameters, run\n",
    "forecaster.get_fitted_params()\n",
    "# should these not include pdq?"
   ]
  },
  {
   "source": [
    "### 2.3 BATS and TBATS\n",
    "\n",
    "`sktime` interfaces BATS and TBATS from the [`tbats`](https://github.com/intive-DataScience/tbats) package."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.bats import BATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = BATS(sp=12, use_trend=True, use_box_cox=False)\n",
    "\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.tbats import TBATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = TBATS(sp=12, use_trend=True, use_box_cox=False)\n",
    "\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "source": [
    "### 2.4 Facebook prophet\n",
    "\n",
    "`sktime` provides an interface to [`fbprophet`](https://github.com/facebook/prophet) by Facebook."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.fbprophet import Prophet"
   ]
  },
  {
   "source": [
    "The current interface does not support period indices, only pd.DatetimeIndex.\n",
    "\n",
    "Consider improving this by contributing the `sktime`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert index to pd.DatetimeIndex\n",
    "z = y.copy()\n",
    "z = z.to_timestamp(freq=\"M\")\n",
    "z_train, z_test = temporal_train_test_split(z, test_size=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = Prophet(\n",
    "    seasonality_mode=\"multiplicative\",\n",
    "    n_changepoints=int(len(y_train) / 12),\n",
    "    add_country_holidays={\"country_name\": \"Germany\"},\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=False,\n",
    "    daily_seasonality=False,\n",
    ")\n",
    "\n",
    "forecaster.fit(z_train)\n",
    "y_pred = forecaster.predict(fh.to_relative(cutoff=y_train.index[-1]))\n",
    "y_pred.index = y_test.index\n",
    "\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "source": [
    "## 3. Advanced composition patterns - pipelines, reduction, autoML, and more\n",
    "\n",
    "Sktime supports a number of advanced composition patterns to create forecasters out of simpler components:\n",
    "\n",
    "* reduction - building a forecaster from estimators of \"simpler\" scientific types, like `scikit-learn` regressors. A common example is feature/label tabulation by rolling window, aka the \"direct reduction strategy\".\n",
    "* tuning - determining values for hyper-parameters of a forecaster in a data-driven manner. A common example is grid search on temporally rolling re-sampling of train/test splits.\n",
    "* pipelining - concatenating transformers with a forecaster to obtain one forecaster. A common example is detrending and deseasonalizing then forecasting, an instance of this is the common \"STL forecaster\".\n",
    "* autoML, also known as automated model selection - using automated tuning strategies to select not only hyper-parameters but entire forecasting strategies. A common example is on-line multiplexer tuning.\n",
    "\n",
    "For illustration, all estimators below will be presented on the basic forecasting workflow - though they also support the advanced forecasting and evaluation workflows under the unified `sktime` interface (see Section 1).\n",
    "\n",
    "For use in the other workflows, simply replace the \"forecaster specification block\" (\"`forecaster=`\") by the forecaster specification block in the examples presented below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports necessary for this chapter\n",
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.utils.plotting import plot_series\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error\n",
    "# data loading for illustration (see section 1 for explanation)\n",
    "y = load_airline()\n",
    "y_train, y_test = temporal_train_test_split(y, test_size=36)\n",
    "fh = ForecastingHorizon(y_test.index, is_relative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Reduction: from forecasting to regression\n",
    "\n",
    "`sktime` provides a meta-estimator that allows the use of any `scikit-learn` estimator for forecasting.\n",
    "\n",
    "* **modular** and **compatible with scikit-learn**, so that we can easily apply any scikit-learn regressor to solve our forecasting problem,\n",
    "* **parametric** and **tuneable**, allowing us to tune hyper-parameters such as the window length or strategy to generate forecasts\n",
    "* **adaptive**, in the sense that it adapts the scikit-learn's estimator interface to that of a forecaster, making sure that we can tune and properly evaluate our model"
   ]
  },
  {
   "source": [
    "**Example**: we will define a tabulation reduction strategy to convert a k-nearest neighbors regressor (`sklearn` `KNeighborsRegressor`) into a forecaster. The composite algorithm is an object compliant with the `sktime` forecaster interface (picture: big robot), and contains the regressor as a parameter accessible component (picture: little robot). In `fit`, the composite algorithm uses a sliding window strategy to tabulate the data, and fit the regressor to the tabulated data (picture: left half). In `predict`, the composite algorithm presents the regressor with the last observed window to obtain predictions (picture: right half).\n",
    "\n",
    "<img src=\"img/forecasting-to-regression-reduction.png\" width=\"500\"/>\n",
    "\n",
    "Below, the composite is constructed using the shorthand function `make_reduction` which produces a `sktime` estimator of forecaster scitype. It is called with a constructed `scikit-learn` regressor, `regressor`, and additional parameter which can be later tuned as hyper-parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sktime.forecasting.compose import make_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = KNeighborsRegressor(n_neighbors=1)\n",
    "forecaster = make_reduction(regressor, window_length=15, strategy=\"recursive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:07.439875Z",
     "iopub.status.busy": "2021-04-10T16:07:07.439381Z",
     "iopub.status.idle": "2021-04-10T16:07:07.650204Z",
     "shell.execute_reply": "2021-04-10T16:07:07.650693Z"
    }
   },
   "outputs": [],
   "source": [
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "source": [
    "In the above example we use the \"recursive\" reduction strategy. Other implemented strategies are: \n",
    "* \"direct\", \n",
    "* \"dirrec\", \n",
    "* \"multioutput\". "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Parameters can be inspected using `scikit-learn` compatible `get_params` functionality (and set using `set_params`). This provides tunable and nested access to parameters of the `KNeighborsRegressor` (as `estimator_etc`), and the `window_length` of the reduction strategy. Note that the `strategy` is not accessible, as underneath the utility function this is mapped on separate algorithm classes. For tuning over algorithms, see the \"autoML\" section below. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.get_params()"
   ]
  },
  {
   "source": [
    "### 3.2 Pipelining, detrending and deseasonalization\n",
    "\n",
    "A common composition motif is pipelining: for example, first deseasonalizing or detrending the data, then forecasting the detrended/deseasonalized series. When forecasting, one needs to add the trend and seasonal component back to the data. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 3.2.1 The basic forecasting pipeline\n",
    "\n",
    "`sktime` provides a generic pipeline object for this kind of composite modelling, the `TransforemdTargetForecaster`. It chains an arbitrary number of transformations with a forecaster. The transformations should be instances of estimators with series-to-series-transformer scitype. An example of the syntax is below:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.compose import TransformedTargetForecaster\n",
    "from sktime.transformations.series.detrend import Deseasonalizer\n",
    "from sktime.forecasting.arima import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = TransformedTargetForecaster(\n",
    "    [\n",
    "        (\"deseasonalize\", Deseasonalizer(model=\"multiplicative\", sp=12)),\n",
    "        (\"forecast\", ARIMA()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "source": [
    "The `TransformedTargetForecaster` is constructed with a list of steps, each a pair of name and estimator. The last estimator should be of forecaster scitype, the other estimators should be series-to-series transformers which possess both a `transform` and `inverse_transform` method. The resulting estimator is of forecaster scitype and has all interface defining methods. In `fit`, all transformers apply `fit_transforms` to the data, then the forecaster's `fit`; in `predict`, first the forecaster's `predict` is applied, then the transformers' `inverse_transform` in reverse order."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 3.2.2 The `Detrender` as pipeline component\n",
    "\n",
    "For detrending, we can use the `Detrender`. This is an estimator of series-to-transformer scitype that wraps an arbitrary forecaster. For example, for linear detrending, we can use `PolynomialTrendForecaster` to fit a linear trend, and then subtract/add it using the `Detrender` transformer inside `TransformedTargetForecaster`.\n",
    "\n",
    "To understand better what happens, we first examine the detrender separately:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from sktime.transformations.series.detrend import Detrender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear detrending\n",
    "forecaster = PolynomialTrendForecaster(degree=1)\n",
    "transformer = Detrender(forecaster=forecaster)\n",
    "yt = transformer.fit_transform(y_train)\n",
    "\n",
    "# internally, the Detrender uses the in-sample predictions\n",
    "# of the PolynomialTrendForecaster\n",
    "forecaster = PolynomialTrendForecaster(degree=1)\n",
    "fh_ins = -np.arange(len(y_train))  # in-sample forecasting horizon\n",
    "y_pred = forecaster.fit(y_train).predict(fh=fh_ins)\n",
    "\n",
    "plot_series(y_train, y_pred, yt, labels=[\"y_train\", \"fitted linear trend\", \"residuals\"]);"
   ]
  },
  {
   "source": [
    "Since the `Detrender` is of scitype series-to-series-transformer, it can be used in the `TransformedTargetForecaster` for detrending any forecaster:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = TransformedTargetForecaster(\n",
    "    [\n",
    "        (\"deseasonalize\", Deseasonalizer(model=\"multiplicative\", sp=12)),\n",
    "        (\"detrend\", Detrender(forecaster=PolynomialTrendForecaster(degree=1))),\n",
    "        (\"forecast\", ARIMA()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "source": [
    "#### 3.2.3 Complex pipeline composites and parameter inspection\n",
    "\n",
    "`sktime` follows the `scikit-learn` philosophy of composability and nested parameter inspection. As long as an estimator has the right scitype, it can be used as part of any composition principle requiring that scitype. Above, we have already seen the example of a forecaster inside a `Detrender`, which is an estimator of scitype series-to-series-transformer, with one component of forecaster scitype. Similarly, in a `TransformedTargetForecaster`, we can use the reduction composite from Section 3.1 as the last forecaster element in the pipeline, which inside has an estimator of tabular regressor scitype, the `KNeighborsRegressor`:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sktime.forecasting.compose import make_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = TransformedTargetForecaster(\n",
    "    [\n",
    "        (\"deseasonalize\", Deseasonalizer(model=\"multiplicative\", sp=12)),\n",
    "        (\"detrend\", Detrender(forecaster=PolynomialTrendForecaster(degree=1))),\n",
    "        (\n",
    "            \"forecast\",\n",
    "            make_reduction(\n",
    "                KNeighborsRegressor(),\n",
    "                scitype=\"tabular-regressor\",\n",
    "                window_length=15,\n",
    "                strategy=\"recursive\",\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "source": [
    "As with `scikit-learn` models, we can inspect and access parameters  of any component via `get_params` and `set_params`:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Parameter tuning\n",
    "\n",
    "`sktime` provides parameter tuning strategies as compositors of forecaster scitype, similar to `scikit-learn`'s `GridSearchCV`."
   ]
  },
  {
   "source": [
    "### 3.3.1 Basic tuning using `ForecastingGridSearchCV`\n",
    "\n",
    "The compositor `ForecastingGridSearchCV` (and other tuners) are constructed with a forecaster to tune, a cross-validation constructor, a `scikit-learn` parameter grid, and parameters specific to the tuning strategy. Cross-validation constructors follow the `scikit-learn` interface for re-samplers, and can be slotted in exchangeably.\n",
    "\n",
    "As an example, we show tuning of the window length in the reduction compositor from Section 3.1, using temporal sliding window tuning:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.compose import make_reduction\n",
    "from sktime.forecasting.model_selection import ForecastingGridSearchCV, SlidingWindowSplitter\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:36.557083Z",
     "iopub.status.busy": "2021-04-10T16:07:36.495720Z",
     "iopub.status.idle": "2021-04-10T16:07:37.096548Z",
     "shell.execute_reply": "2021-04-10T16:07:37.097150Z"
    }
   },
   "outputs": [],
   "source": [
    "regressor = KNeighborsRegressor()\n",
    "forecaster = make_reduction(regressor, window_length=15, strategy=\"recursive\")\n",
    "param_grid = {\"window_length\": [7, 12, 15]}\n",
    "\n",
    "# We fit the forecaster on an initial window which is 80% of the historical data\n",
    "# then use temporal sliding window cross-validation to find the optimal hyper=parameters.\n",
    "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.8), window_length=20)\n",
    "gscv = ForecastingGridSearchCV(\n",
    "    forecaster, strategy=\"refit\", cv=cv, param_grid=param_grid\n",
    ")"
   ]
  },
  {
   "source": [
    "As with other composites, the resulting forecaster provides the unified interface of `sktime` forecasters - window splitting, tuning, etc requires no manual effort and is done behind the unified interface:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:37.120099Z",
     "iopub.status.busy": "2021-04-10T16:07:37.100367Z",
     "iopub.status.idle": "2021-04-10T16:07:37.372802Z",
     "shell.execute_reply": "2021-04-10T16:07:37.372246Z"
    }
   },
   "outputs": [],
   "source": [
    "gscv.fit(y_train)\n",
    "y_pred = gscv.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "source": [
    "Tuned parameters can be accessed in the `best_params_` attribute:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:37.375928Z",
     "iopub.status.busy": "2021-04-10T16:07:37.375391Z",
     "iopub.status.idle": "2021-04-10T16:07:37.377362Z",
     "shell.execute_reply": "2021-04-10T16:07:37.377899Z"
    }
   },
   "outputs": [],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "source": [
    "An instance of the best forecaster, with hyper-parameters set, can be retrieved by accessing the `best_forecaster_` attribute:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_forecaster_"
   ]
  },
  {
   "source": [
    "### 3.3.2 Tuning of complex composites\n",
    "\n",
    "As in `scikit-learn`, parameters of nested components can be tuned by accessing their `get_params` key - by default this is `[estimatorname]__[parametername]` if `[estimatorname]` is the name of the component, and `[parametername]` the name of a parameter within the estimator `[estimatorname]`. \n",
    "\n",
    "For example, below we tune the `KNeighborsRegressor` component's `n_neighbors`, in addition to tuning `window_length`. The tuneable parameters can easily be queried using `forecaster.get_params()`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.compose import make_reduction\n",
    "from sktime.forecasting.model_selection import ForecastingGridSearchCV, SlidingWindowSplitter\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"window_length\": [7, 12, 15], \"estimator__n_neighbors\" : np.arange(1,10) }\n",
    "\n",
    "regressor = KNeighborsRegressor()\n",
    "forecaster = make_reduction(\n",
    "    regressor, scitype=\"tabular-regressor\", strategy=\"recursive\"\n",
    ")\n",
    "\n",
    "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.8), window_length=30)\n",
    "gscv = ForecastingGridSearchCV(forecaster, cv=cv, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.fit(y_train)\n",
    "y_pred = gscv.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "source": [
    "An alternative to the above is tuning the regressor separately, using `scikit-learn`'s `GridSearchCV` and a separate parameter grid. As this does not use the \"overall\" performance metric to tune the inner regressor, performance of the composite forecaster may vary."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# tuning the 'n_estimator' hyperparameter of RandomForestRegressor from scikit-learn\n",
    "regressor_param_grid = {\"n_neighbors\" : np.arange(1,10)}\n",
    "forecaster_param_grid = {\"window_length\": [7, 12, 15]}\n",
    "\n",
    "# create a tunnable regressor with GridSearchCV\n",
    "regressor = GridSearchCV(KNeighborsRegressor(), param_grid=regressor_param_grid)\n",
    "forecaster = make_reduction(\n",
    "    regressor, scitype=\"tabular-regressor\", strategy=\"recursive\"\n",
    ")\n",
    "\n",
    "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.8), window_length=30)\n",
    "gscv = ForecastingGridSearchCV(forecaster, cv=cv, param_grid=forecaster_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.fit(y_train)\n",
    "y_pred = gscv.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "source": [
    "NOTE: a smart implementation of this would use caching to save partial results from the inner tuning and reduce runtime substantially - currently `sktime` does not support this. Consider helping to improve `sktime`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 3.3.3 Selecting the metric and retrieving scores\n",
    "\n",
    "All tuning algorithms in `sktime` allow the user to set a score; for forecasting the default is mean absolute percentage error. The score can be set using the `score` argument, to any scorer function or class, as in Section 1.3.\n",
    "\n",
    "Re-sampling tuners retain performances on individual forecast re-sample folds, which can be retrieved from the `cv_results_` argument after the forecaster has been fit via a call to `fit`.\n",
    "\n",
    "In the above example, using the mean squared error instead of the mean absolute percentage error for tuning would be done by defining the forecaster as follows:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = MeanSquaredError()\n",
    "\n",
    "param_grid = {\"window_length\": [7, 12, 15]}\n",
    "\n",
    "regressor = KNeighborsRegressor()\n",
    "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.8), window_length=30)\n",
    "\n",
    "gscv = ForecastingGridSearchCV(\n",
    "    forecaster, cv=cv, param_grid=param_grid, scoring=mse\n",
    ")"
   ]
  },
  {
   "source": [
    "The performances on individual folds can be accessed as follows, after fitting:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.fit(y_train)\n",
    "gscv.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.4 autoML  aka automated model selection, ensembling and hedging\n",
    "\n",
    "`sktime` provides a number of compositors for ensembling and automated model selection. In contrast to tuning, which uses data-driven strategies to find optimal hyper-parameters for a fixed forecaster, the strategies in this section combine or select on the level of estimators, using a collection of forecasters to combine or select from.\n",
    "\n",
    "The strategies discussed in this section are:\n",
    "* autoML aka automated model selection\n",
    "* simple ensembling\n",
    "* prediction weighted ensembles with weight updates, and hedging strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.4.1 autoML aka automatic model selection, using tuning plus multiplexer\n",
    "\n",
    "The most flexible way to perform model selection over forecasters is by using the `MultiplexForecaster`, which exposes the choice of a forecaster from a list as a hyper-parameter that is tunable by generic hyper-parameter tuning strategies such as in Section 3.3.\n",
    "\n",
    "In isolation, `MultiplexForecaster` is constructed with a named list `forecasters`, of forecasters. It has a single hyper-parameter, `selected_forecaster`, which can be set to the name of any forecaster in `forecasters`, and behaves exactly like the forecaster keyed in `forecasters` by `selected_forecaster`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.compose import MultiplexForecaster\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.forecasting.exp_smoothing import ExponentialSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:14:33.332255Z",
     "iopub.status.busy": "2021-04-10T16:14:33.310571Z",
     "iopub.status.idle": "2021-04-10T16:14:34.759567Z",
     "shell.execute_reply": "2021-04-10T16:14:34.760081Z"
    }
   },
   "outputs": [],
   "source": [
    "forecaster = MultiplexForecaster(\n",
    "    forecasters=[\n",
    "        (\"naive\", NaiveForecaster(strategy=\"last\")),\n",
    "        (\"ets\", ExponentialSmoothing(trend=\"add\", sp=12)),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.set_params(**{'selected_forecaster' : 'naive'})\n",
    "# now forecaster behaves like NaiveForecaster(strategy=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.set_params(**{'selected_forecaster' : 'ets'})\n",
    "# now forecaster behaves like ExponentialSmoothing(trend=\"add\", sp=12))"
   ]
  },
  {
   "source": [
    "The `MultiplexForecaster` is not too useful in isolation, but allows for flexible autoML when combined with a tuning wrapper. The below defines a forecaster that selects one of `NaiveForecaster` and `ExponentialSmoothing` by sliding window tuning as in Section 3.3.\n",
    "\n",
    "Combined with rolling use of the forecaster via the `update` functionality (see Section 1.4), the tuned multiplexer can switch back and forth between `NaiveForecaster` and `ExponentialSmoothing`, depending on performance, as time progresses."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_selection import ForecastingGridSearchCV, SlidingWindowSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = MultiplexForecaster(\n",
    "    forecasters=[\n",
    "        (\"naive\", NaiveForecaster(strategy=\"last\")),\n",
    "        (\"ets\", ExponentialSmoothing(trend=\"add\", sp=12)),\n",
    "    ]\n",
    ")\n",
    "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.5), window_length=30)\n",
    "forecaster_param_grid = {\"selected_forecaster\": [\"ets\", \"naive\"]}\n",
    "gscv = ForecastingGridSearchCV(forecaster, cv=cv, param_grid=forecaster_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.fit(y_train)\n",
    "y_pred = gscv.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "source": [
    "As with any tuned forecaster, best parameters and an instance of the tuned forecaster can be retrieved using `best_params_` and `best_forecaster_`:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:14:35.007827Z",
     "iopub.status.busy": "2021-04-10T16:14:35.007334Z",
     "iopub.status.idle": "2021-04-10T16:14:35.009284Z",
     "shell.execute_reply": "2021-04-10T16:14:35.009782Z"
    }
   },
   "outputs": [],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_forecaster_"
   ]
  },
  {
   "source": [
    "###  3.4.2 simple ensembling strategies\n",
    "\n",
    "TODO"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:07:36.322267Z",
     "iopub.status.busy": "2021-04-10T16:07:36.287424Z",
     "iopub.status.idle": "2021-04-10T16:07:36.486587Z",
     "shell.execute_reply": "2021-04-10T16:07:36.487094Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ses = ExponentialSmoothing(sp=12)\n",
    "holt = ExponentialSmoothing(trend=\"add\", damped_trend=False, sp=12)\n",
    "damped = ExponentialSmoothing(trend=\"add\", damped_trend=True, sp=12)\n",
    "\n",
    "forecaster = EnsembleForecaster(\n",
    "    [\n",
    "        (\"ses\", ses),\n",
    "        (\"holt\", holt),\n",
    "        (\"damped\", damped),\n",
    "    ]\n",
    ")\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:11:08.750593Z",
     "iopub.status.busy": "2021-04-10T16:11:08.750113Z",
     "iopub.status.idle": "2021-04-10T16:11:08.751762Z",
     "shell.execute_reply": "2021-04-10T16:11:08.752258Z"
    }
   },
   "outputs": [],
   "source": [
    "print(gscv.best_params_, gscv.best_forecaster_.estimator_.best_params_)"
   ]
  },
  {
   "source": [
    "### 3.4.3 Prediction weighted ensembles and hedge ensembles\n",
    "\n",
    "For model evaluation, we sometimes want to evaluate multiple forecasts, using temporal cross-validation with a sliding window over the test data. For this purpose, we can leverage the forecasters from the `online_forecasting` module which use a composite forecaster, `PredictionWeightedEnsemble`, to keep track of the loss accumulated by each forecaster and create a prediction weighted by the predictions of the most \"accurate\" forecasters.\n",
    "\n",
    "Note that the forecasting task is changed: we make 35 predictions since we need the first prediction to help update the weights, we do not predict 36 steps ahead."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:14:39.872044Z",
     "iopub.status.busy": "2021-04-10T16:14:39.871304Z",
     "iopub.status.idle": "2021-04-10T16:14:39.874814Z",
     "shell.execute_reply": "2021-04-10T16:14:39.875324Z"
    }
   },
   "outputs": [],
   "source": [
    "from sktime.forecasting.all import mean_squared_error\n",
    "from sktime.forecasting.online_learning import (\n",
    "    NormalHedgeEnsemble,\n",
    "    OnlineEnsembleForecaster,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to initialize a `PredictionWeightedEnsembler` that will keep track of the loss accumulated by each forecaster and define which loss function we would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:14:39.878435Z",
     "iopub.status.busy": "2021-04-10T16:14:39.877913Z",
     "iopub.status.idle": "2021-04-10T16:14:39.879324Z",
     "shell.execute_reply": "2021-04-10T16:14:39.879979Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hedge_expert = NormalHedgeEnsemble(n_estimators=3, loss_func=mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can then create the forecaster by defining the individual forecasters and specifying the `PredictionWeightedEnsembler` we are using. Then by fitting our forecasters and performing updates and prediction with the `update_predict` function, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:14:39.923246Z",
     "iopub.status.busy": "2021-04-10T16:14:39.920259Z",
     "iopub.status.idle": "2021-04-10T16:14:40.917504Z",
     "shell.execute_reply": "2021-04-10T16:14:40.918060Z"
    }
   },
   "outputs": [],
   "source": [
    "forecaster = OnlineEnsembleForecaster(\n",
    "    [\n",
    "        (\"ses\", ses),\n",
    "        (\"holt\", holt),\n",
    "        (\"damped\", damped),\n",
    "    ],\n",
    "    ensemble_algorithm=hedge_expert,\n",
    ")\n",
    "\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.update_predict(y_test)\n",
    "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "mean_absolute_percentage_error(y_test[1:], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction intervals\n",
    "So far, we've only looked at point forecasts. In many cases, we're also interested in prediction intervals. `sktime`'s interface support prediction intervals, but we haven't implemented them for all algorithms yet.\n",
    "\n",
    "Here, we use the Theta forecasting algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:14:40.934978Z",
     "iopub.status.busy": "2021-04-10T16:14:40.934373Z",
     "iopub.status.idle": "2021-04-10T16:14:40.937008Z",
     "shell.execute_reply": "2021-04-10T16:14:40.937503Z"
    }
   },
   "outputs": [],
   "source": [
    "forecaster = ThetaForecaster(sp=12)\n",
    "forecaster.fit(y_train)\n",
    "alpha = 0.05  # 95% prediction intervals\n",
    "y_pred, pred_ints = forecaster.predict(fh, return_pred_int=True, alpha=alpha)\n",
    "mean_absolute_percentage_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-10T16:14:40.970332Z",
     "iopub.status.busy": "2021-04-10T16:14:40.962229Z",
     "iopub.status.idle": "2021-04-10T16:14:41.157733Z",
     "shell.execute_reply": "2021-04-10T16:14:41.158242Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "ax.fill_between(\n",
    "    ax.get_lines()[-1].get_xdata(),\n",
    "    pred_ints[\"lower\"],\n",
    "    pred_ints[\"upper\"],\n",
    "    alpha=0.2,\n",
    "    color=ax.get_lines()[-1].get_c(),\n",
    "    label=f\"{1 - alpha}% prediction intervals\",\n",
    ")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "As we have seen, in order to make forecasts, we need to first specify (or build) a model, then fit it to the training data, and finally call predict to generate forecasts for the given forecasting horizon.\n",
    "\n",
    "* `sktime` comes with several forecasting algorithms (or forecasters) and tools for composite model building. All forecaster share a common interface. Forecasters are trained on a single series of data and make forecasts for the provided forecasting horizon.\n",
    "\n",
    "* `sktime` has a number of statistical forecasting algorithms, based on implementations in statsmodels. For example, to use exponential smoothing with an additive trend component and multiplicative seasonality, we can write the following.\n",
    "\n",
    "\n",
    "## Useful resources\n",
    "* For more details, take a look at [our paper on forecasting with sktime](https://arxiv.org/abs/2005.08067) in which we discuss the forecasting API in more detail and use it to replicate and extend the M4 study.\n",
    "* For a good introduction to forecasting, see [Hyndman, Rob J., and George Athanasopoulos. Forecasting: principles and practice. OTexts, 2018](https://otexts.com/fpp2/).\n",
    "* For comparative benchmarking studies/forecasting competitions, see the [M4 competition](https://www.sciencedirect.com/science/article/pii/S0169207019301128) and the [M5 competition](https://www.kaggle.com/c/m5-forecasting-accuracy/overview)."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0bc250fec99d1b72e5bb23d9fb06e1f1ac90e860438a1535c061277d2caf5ebfc",
   "display_name": "Python 3.7.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}